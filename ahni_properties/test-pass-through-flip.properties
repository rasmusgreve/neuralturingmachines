# Sample properties file describing most available properties for AHNI.
# This sample properties file uses a transcriber that creates GridNet neural networks 
# (com.ojcoleman.ahni.transcriber.HyperNEATTranscriberGridNet).  
# The GridNet transcriber is no longer under active development, the recommended transcriber for HyperNEAT is
# com.ojcoleman.ahni.transcriber.HyperNEATTranscriberBain (see the sample properties file 
# bain-test-pass-through-flip.properties).

# The seed to use for the random number generator that is used for generating ALL random numbers in an experiment.
# Thus if the same seed is used you should see the same results every time (ie reproducibility). Comment out to use a
# seed based on the time; this is generally required when performing multiple runs (when num.runs > 0), otherwise every run
# will turn out exactly the same. 
#random.seed=1234567
run.name=test-pass-through-flip
run.reset=true

###########
# evolution
###########
#The number of evolution runs to perform.
num.runs=1
#The number of generations (fitness evaluations followed by generation of the next population) to perform per evolution run.
num.generations=5000
#The number of individuals in the population.
popul.size=250

#When this performance level (which is proportional to the fitness unless an experiment defines its own performance metric) is reached evolution will stop.
performance.target=1
#"higher" indicates that the performance should increase over the course of evolution, "lower" that it should decrease. 
performance.target.type=higher

#false means mutation probabilities are applied to all possible places a mutation could occur
#true means probabilities apply to individual as a whole; only one topological mutation can occur per individual
#note that this applies only to topological mutations, not weight mutations
topology.mutation.classic=true

#classic=[0.01, 0.5], not classic=[0.0001,] dependent on pop size. 0.03
add.neuron.mutation.rate=0.25
#classic=[0.01, 0.5], not classic=[0.0001,] dependent on pop size. 0.4
add.connection.mutation.rate=0.5
#[0.01, 0.3]
remove.connection.mutation.rate=0.02
#only remove weights with magnitude smaller than this
remove.connection.max.weight=50

#should be 1.0
prune.mutation.rate=1.0

#[0.1, 0.8]. 0.5, 0.6
weight.mutation.rate=0.1
#[1.0, 2.0] dependent on weight.max/min?
weight.mutation.std.dev=1.0
# The amount to perturb weights by when generating the initial population. Default is weight.mutation.std.dev
weight.mutation.std.dev.initial=0.5


# percent of individuals used as parents
survival.rate=0.3
# proportion of sexual (crossover) versus asexual reproduction
crossover.proportion=0.5
# the probability that an individual produced by the crossover operator will be a candidate for having mutations applied to it (independent of other mutation probabilities).
crossover.mutate.probability=0

#[1, 5]
selector.elitism.min.specie.size=5
#percent of individuals from each species copied to next generation unchanged
selector.elitism.proportion=0.0
#min number to select from a species (if it has size >=  selector.elitism.min.specie.size)
selector.elitism.min.to.select=1
selector.roulette=false
# Whether to use speciated fitness.
selector.speciated.fitness=true
# The maximum number of generations a species can exist for without fitness improvement
# (unless it's the only species or it's the fittest and selector.max.stagnant.maintainfittest=true) 
selector.max.stagnant.generations=15
selector.max.stagnant.maintainfittest=true


############
# speciation
############
#species distance factors
#c1, excess genes factor [1.0, 2.0]
chrom.compat.excess.coeff=2.0
#c2, disjoint genes factor [1.0, 2.0]
chrom.compat.disjoint.coeff=2.0
#c3, Weight difference factor [0.2, 3.0]
chrom.compat.common.coeff=1.0

#compatability threshold [0.1, 4.0], relative to c#
speciation.threshold=2.0
speciation.target=15
speciation.threshold.change=0.1


##################
# fitness function
##################
#The fully qualified class name (ie including packages) that will be used to evaluate fitness
fitness_function.class=com.ojcoleman.ahni.experiments.TestTargetFitnessFunction
#max threads to use for fitness evaluation (including transcription of genotype/cppn to phenotype/substrate)
#if value is <= 0 then the detected number of processor cores will be used
fitness.max_threads=0
#if fitness.hyperneat.scale.factor > 1 and fitness.hyperneat.scale.times > 0 
#then the substrate height, width and connection.range will be multiplied 
#by fitness.hyperneat.scale.factor every time fitness.hyperneat.scale.fitness 
#is reached, at most fitness.hyperneat.scale.times times.
fitness.hyperneat.scale.factor=2
fitness.hyperneat.scale.times=0
fitness.hyperneat.scale.performance=0.98
fitness.hyperneat.scale.recordintermediateperformance=true

#experiment specific
fitness.function.test.type=pass-through-flip
# See com.ojcoleman.ahni.util.TargetFitnessCalculator.ErrorType for a description of the available error calculation methods.
fitness.function.error.type.output=SAE
# See com.ojcoleman.ahni.util.TargetFitnessCalculator.ErrorType for a description of the available error calculation methods.
fitness.function.error.type.trial=SAE
# The method for calculating a fitness value from the error value. Valid types are:
#   proportional: The fitness is calculated as MAX_FITNESS * (error / MAX_ERROR), where MAX_FITNESS is some large constant and MAX_ERROR is the maximum possible error value. This is the default.
#   inverse: The fitness is calculated as MAX_FITNESS / (1 + error), where MAX_FITNESS is some large constant.
fitness.function.error.conversion.type=inverse
# The method used to calculate the performance. 
#   proportional: The performance is calculated as <em>error / MAX_ERROR</em>, where MAX_ERROR is the maximum possible error value. This is the default.
#   percent-correct: The performance is calculated as the percentage of correct trials (see {@link FITNESS_ACCEPTABLE_ERROR_KEY}).
fitness.function.performance.type=proportional
# The absolute value that an output can differ from the target output and still be considered correct (i.e. the acceptable error margin). Used for calculating the percentage of trials for which the correct output was given. Default is 0.1.
fitness.function.error.acceptable=0.1
# Whether to log the evaluation of the champ for each trial to a text file: N < 0 indicates no logging, N=0 indicates 
# only at the end of evolution, N > 0 indicates every N generations and after evolution has finished.
fitness.function.log.champ.evaluation.pergenerations=25


################
# CPPN/AnjiNet #
################
#input and output size determined by hyperneat settings
#stimulus.size=7
#response.size=1
# The type of activation function to use in the CPPN, "random" means a function will be randomly picked.
initial.topology.activation=random
initial.topology.fully.connected=true
initial.topology.num.hidden.neurons=0
initial.topology.activation.input=linear
initial.topology.activation.output=linear
# The activation function types that may be added to the CPPN if initial.topology.activation=random.
initial.topology.activation.random.allowed=sigmoid, gaussian, sine, absolute
# The probability weight of each function in initial.topology.activation.random.allowed being selected.
#initial.topology.activation.random.probabilities=1.0, 1.0, 1.0, 1.0
recurrent=disallowed
recurrent.cycles=1
#[1, 500]
weight.max=50
weight.min=-50


#####################
# HyperNEAT/GridNet #
#####################
#The class that will perform the transcription from a chromosome/individual describing a CPPN to the substrate network.
ann.transcriber.class=com.ojcoleman.ahni.transcriber.HyperNEATTranscriberGridNet
#The activation function to use for neurons in the substrate network. Typically "sigmoid". See com.anji.nn.activationfunction.ActivationFunctionFactory
ann.hyperneat.activation.function=clamped-linear
#Set to true to restrict the substrate network to a strictly feed-forward topology.
ann.hyperneat.feedforward=true
#For recurrent networks, the number of activation cycles to perform each time the substrate network is presented with new input and queried for its output.
#ann.hyperneat.cyclesperstep=4  not required for feed forward
#Enable bias connections in the substrate network.
ann.hyperneat.enablebias=true
#If true indicates that the CPPN should receive the delta value for each axis between the source and target neuron coordinates
ann.hyperneat.includedelta=true
#If true indicates that the CPPN should receive the angle in the XY plane between the source and target neuron coordinates (relative to the line X axis).
ann.hyperneat.includeangle=false
#If true indicates that instead of using a separate output from the CPPN to specify weight values for each weight layer in a feed-forward network, the layer coordinate is input to the CPPN and only a single output from CPPN is used to specify weight values for all weight layers.
ann.hyperneat.useinputlayerencoding=false

#The minimum CPPN output required to produce a non-zero weight in the substrate network. 
ann.hyperneat.connection.expression.threshold=0.2
# If true use the Link Expression Output enhancement instead of a threshold (ie instead of ann.hyperneat.connection.expression.threshold)
ann.hyperneat.leo=false
# Enable or disable seeding of the initial population of CPPNs to incorporate a bias towards local connections via the Link Expression Output (LEO). Default is "false".
ann.hyperneat.leo.localityseeding=false

#Limits the incoming connections to a target neuron to include those from source neurons within the specified range of the target neuron. Set this to -1 to disable it.
ann.hyperneat.connection.range=-1
#Minimum and maximum weight values in the substrate network.
ann.transcriber.connection.weight.min=-1
ann.transcriber.connection.weight.max=1

#The number of layers in the substrate network.
ann.hyperneat.depth=2
#The height and width of each layer in the network, including input and output layers and starting with the input layer.
ann.hyperneat.height=2, 2
ann.hyperneat.width=2, 2

# The coordinate range of neurons in the substrate in each dimension. This is 
# used to determine the input to the CPPN for a given substrate neuron location. 
# Defaults to "0, 1".
ann.hyperneat.range.x=0, 1
ann.hyperneat.range.y=0, 1
# Inputs are at z=0, outputs at z=1.
ann.hyperneat.range.z=0, 1 

# The coordinates of neurons in a specified layer. The layer must be specified as part of the property key/name,
# e.g. to specify the coordinates of two neurons in the layer with index 2 (counting from 0):
#   ann.hyperneat.layer.positions.2=(-0.5, 0, 0), (0.5, 0, 0)
# For 2D layers the coordinates should be specified in row-packed order (i.e. one row after another, where a single
# row has the same y index/coordinate). Coordinates must be specified for all neurons in the given layer. If the z
# coordinate is not given it will be set to the default for the layer.
 # NOTE: coordinates should be given with respect to ann.hyperneat.range settings.
#ann.hyperneat.layer.positions.2=(-0.5, 0, 0), (0.5, 0, 0)

# Optionally specify an initial seed CPPN from which the initial population is created.
# Each entry either specifies a hidden neuron or a connection. Entries are comma-separated, 
# with the parameters for each entry separated by colons (:). The parameters for a hidden 
# neuron are an ID and the activation function, for example "my hidden 2:sigmoid" (the ID can
# be anything except for the IDs listed below for input and output neurons). The parameters 
# for a connection are a "c" to indicate this is a connection entry, the source neuron, the 
# target neuron and the weight, for example "c:xs:my hidden 2:-0.5". Input and output neurons
# use the following labelling scheme:
# b: CPPN bias input
# [xyz][st]: x, y or z coordinate input for source or target neuron.
# wN: weight output for source layer N, counting from 0 (N=0 if ann.hyperneat.useinputlayerencoding=true).
# wB: bias output for source layer N, counting from 0 (N=0 if ann.hyperneat.useinputlayerencoding=true).
# wL: LEO output for source layer N, counting from 0 (N=0 if ann.hyperneat.useinputlayerencoding=true).
# Note that the available inputs and outputs is dependent on other parameters.
# Example (note that property values can span multiple lines by ending each line with \):
#hyperneat.cppn.initial=\
#h0:gaussian, \
#h1:gaussian, \
#h2:sigmoid, \
#h3:step, \
#c:xs:h1:1, \
#c:zs:h0:1, \
#c:xt:h1:-1, \
#c:zt:h0:-1, \
#c:b:h0:1, \
#c:b:h3:-1, \
#c:h0:h2:1, \
#c:h1:h3:1, \
#c:h2:w0:1, \
#c:h3:l0:1


#############
# persistence
#############
persistence.class=com.anji.persistence.FilePersistence
persistence.base.dir=./db
persist.enable=false
persist.all=false
persist.champions=false
persist.last=false
persist.load.genotype=false
id.file=./db/id.xml
neat.id.file=./db/neatid.xml

##############
# presentation
##############
presentation.generate=false
presentation.dir=./nevt

#########
# logging
#########
# How often to produce a line in the log containing a brief summary of the current progress.
log.pergenerations=1

# FileAppenders with the name RunLog receive special treatment: for each run the output will be directed to a file 
# with the name specified by log4j.appender.RunLog.File in the directory [output.dir]/[run number]/
log4j.rootLogger=INFO, C
log4j.appender.C=org.apache.log4j.ConsoleAppender
#log4j.appender.F=org.apache.log4j.FileAppender
#log4j.appender.F=org.apache.log4j.RollingFileAppender
#log4j.appender.F.File=/home/data/ai/unsw/project/software/anji/log/or3.log
#log4j.appender.F.MaxFileSize=10MB
#log4j.appender.F.MaxBackupIndex=20
log4j.appender.C.layout=org.apache.log4j.PatternLayout
#log4j.appender.F.layout=org.apache.log4j.PatternLayout
log4j.appender.C.layout.ConversionPattern=%-5p %m%x%n
#log4j.appender.F.layout.ConversionPattern=%-5p %m%x%n

################
# other output #
################
# Where to store output files produced by the experiment.
output.dir=../test-pass-through-flip
# Whether to log the champ to a text file and/or image. N < 0 indicates no logging, N=0 indicates 
# only at the end of evolution, N > 0 indicates every N generations and after evolution has finished.
log.champ.tostring=25
log.champ.toimage=25
log.champ.evaluation=25