# Sample properties file describing most available properties for AHNI.
# This sample properties file uses a transcriber that creates Bain neural networks 
# (com.ojcoleman.ahni.transcriber.HyperNEATTranscriberBain), and demonstrates the properties provided by this
# transcriber to allow setting neuron and synapse model parameters as well as a few other properties and settings
# currently provided only by this transcriber (since the GridNet transcriber is no longer under active development).  


# The seed to use for the random number generator that is used for generating ALL random numbers in an experiment.
# Thus if the same seed is used you should see the same results every time (ie reproducibility). Comment out to use a
# seed based on the time; this is generally required when performing multiple runs (when num.runs > 0), otherwise every run
# will turn out exactly the same. 
#random.seed=1234567

# Optional property key. ID of current experiment (constant over all runs). Must be an integer value (Long is 
# acceptable). If not given then current system time in milliseconds is used.
#experiment.id=1234

run.name=bain-test-pass-through-flip
run.reset=true

# Optional property. A comma-separated list of property files to include (minus the '.properties' extension). In the 
# event of the same property being defined by both the including and included file, the properties in the including 
# file will override properties defined in the included file.
#properties.include=properties/neat-hn, properties/network-soltoggio, properties/misc

# If set to "true" then substitutions present in property values will be enabled. Substitutions have the format $([key]), where [key] is the key of another property, for example:
# myProp1=foo
# myProp2=$(myProp2)
# will replace "$(myProp2)" with "foo". Multiple substitutions may be used for the same property, and other characters may surround a substitution:
# myProp1=foo
# myProp2=bar$(myProp1)baz
# myProp3=$(myProp2)$(myProp3)
substitution.enable=false

###########
# evolution
###########

# The path to a seed chromosome file to use. The file should contain an XML description of the chromosome in the same 
# format as that in the initial-sample-chromosome.txt output files. The seed chromosome is included intact in the
# initial population.
#chrom.seed=../my_seed_chrom.xml

#The number of evolution runs to perform.
num.runs=1
#The number of generations (fitness evaluations followed by generation of the next population) to perform per evolution run.
num.generations=5000
#The number of individuals in the population.
popul.size=250

#When this performance level (which is proportional to the fitness unless an experiment defines its own performance metric) is reached evolution will stop.
performance.target=1
#"higher" indicates that the performance should increase over the course of evolution, "lower" that it should decrease. 
performance.target.type=higher

# true means probabilities apply to individual as a whole; only one topological mutation can occur per individual (as in original NEAT).
# false means topological mutation probabilities are interpreted individually, and if the mutation rate is > 1 then 
# more than one mutation of the same kind may occur.
topology.mutation.classic=false

# Mutation rate for original NEAT add neuron topological mutation where a neuron replaces an existing connection. 
add.neuron.mutation.rate=0

# Mutation rate for operator that adds neurons anywhere in the network (as opposed to regular add neuron operator that 
# only adds them in place of existing connections). Only works for topology.mutation.classic=false
add.neuron.anywhere.mutation.rate=0.25

add.connection.mutation.rate=0.8
#[0.01, 0.3]
remove.connection.mutation.rate=0.02
#only remove weights with magnitude smaller than this
remove.connection.max.weight=1

#should be 1.0
prune.mutation.rate=1.0

#[0.1, 0.8]. 0.5, 0.6
weight.mutation.rate=0.1
#[1.0, 2.0] dependent on weight.max/min?
weight.mutation.std.dev=0.5
# The amount to perturb weights by when generating the initial population. Default is weight.mutation.std.dev
weight.mutation.std.dev.initial=0.5


# percent of individuals used as parents
survival.rate=0.3
# proportion of sexual (crossover) versus asexual reproduction
crossover.proportion=0.4
# the probability that an individual produced by the crossover operator will be a candidate for having mutations applied to it (independent of other mutation probabilities).
crossover.mutate.probability=0

#[1, 5]
selector.elitism.min.specie.size=1
#percent of individuals from each species copied to next generation unchanged
selector.elitism.proportion=0.1
#min number to select from a species (if it has size >=  selector.elitism.min.specie.size)
selector.elitism.min.to.select=0
selector.roulette=false
# Whether to use speciated fitness.
selector.speciated.fitness=true
# The maximum number of generations a species can exist for without performance improvement. Default is Integer.MAX_VALUE 
selector.max.stagnant.generations=15
selector.max.stagnant.maintainfittest=true


############
# speciation
############
#species distance factors
#c1, excess genes factor [1.0, 2.0]
chrom.compat.excess.coeff=2.0
#c2, disjoint genes factor [1.0, 2.0]
chrom.compat.disjoint.coeff=2.0
#c3, Weight difference factor [0.2, 3.0]
chrom.compat.common.coeff=1.0

# enable chromosome compatibility normalisation (default is false)
# (if true then disjoint and excess distance are divided by size of larger genome and weight difference is averaged over shared connections). 
chrom.compat.normalise=false

# If set to true then the current values (weight, bias) of excess and disjoint alleles/genes will be summed (and then 
# multiplied by their respective coefficients), instead of simply counting the number of excess/disjoint genes.
chrom.compat.mismatch_use_values=true

# The class to use that implements a speciation strategy. 
# Default is com.anji.neat.SpeciationStrategyOriginal (which implements the speciation strategy described in the original NEAT).
speciation.class=com.anji.neat.SpeciationStrategyKMeans

#compatability threshold [0.1, 4.0], relative to c#
speciation.threshold=2.0
# Target number of species, default is popul.size ^ 0.6 (bit more than square root)
speciation.target=15


##################
# fitness function
##################
#The fully qualified class name (ie including packages) that will be used to evaluate fitness
fitness_function.class=com.ojcoleman.ahni.experiments.TestTargetFitnessFunction
#max threads to use for fitness evaluation (including transcription of genotype/cppn to phenotype/substrate)
#if value is <= 0 then the detected number of processor cores will be used
fitness.max_threads=0


# Transcription and evaluation may be performed by a cluster of computers using the "minion" system. 
# The fitness function must be based on com.ojcoleman.ahni.evaluation.BulkFitnessFunctionMT.
# In a minion set-up the initial instance of AHNI controls one or more minion instances and doesn't perform any 
# transcriptions or evaluations itself. The controller and minions communicate via sockets, with each minion instance 
# acting as a server which waits for requests from the controlling instance. Minions create a log file
# called <output.dir>/minion.<hostname>.log relative to the file system on the machine they're running on.

# A comma-separated list of host names and ports of minion instances. A user name must be prepended if minion.autostart 
# is enabled, in which case the user name is used during the ssh login to the minion machine. A range of host names may 
# be specified by including a numeric range of the form [<start>-<end>], for example hubert[09-11]:1234 (giving 
# hubert09, hubert10, hubert11) or foo[8-10]bar (giving foo8bar, foo9bar, foo10bar), note that left-padding of the 
# numbers will only occur if the <start> number is padded in the definition. If no port is specified then 
# minion.default_port will be used.
# Alternatively this can be set to "[htcondor:<N>]" to indicate that Minions should be managed by HTCondor, where N is 
# the number of Minions to start. Use of HTCondor forces minion.autostart=TRUE. NOTE: use of HTCondor was an experiment 
# that couldn't be completed. You can try it out, but keep in mind that it hasn't been properly tested.
#minion.hosts=localhost, oliver@hubert[00-14]:2122
#minion.hosts=[htcondor:16]

# On *nix machines the controlling instance can optionally automatically launch - via ssh commands - minion instances 
# configured to serve it, restarting minion instances if they die (for example if a machine is reset). If this is
# enabled then the minion instances will be automatically terminated when the controlling instance terminates.
# Alternatively Minions can be manually started with a command like 
# java -cp <jar file(s)> com.ojcoleman.ahni.evaluation.Minion --port 1234 --log logfilename
#minion.autostart=true

# The default port that minions should use, if not specified in minion.hosts
#minion.default_port=2113


#if fitness.hyperneat.scale.factor > 1 and fitness.hyperneat.scale.times > 0 
#then the substrate height, width and connection.range will be multiplied 
#by fitness.hyperneat.scale.factor every time fitness.hyperneat.scale.fitness 
#is reached, at most fitness.hyperneat.scale.times times.
fitness.hyperneat.scale.factor=2
fitness.hyperneat.scale.times=0
fitness.hyperneat.scale.performance=0.98
fitness.hyperneat.scale.recordintermediateperformance=true

#experiment specific
fitness.function.test.type=pass-through-flip
# See com.ojcoleman.ahni.util.TargetFitnessCalculator.ErrorType for a description of the available error calculation methods.
fitness.function.error.type.output=SAE
# See com.ojcoleman.ahni.util.TargetFitnessCalculator.ErrorType for a description of the available error calculation methods.
fitness.function.error.type.trial=SAE
# The method for calculating a fitness value from the error value. Valid types are:
#   proportional: The fitness is calculated as MAX_FITNESS * (error / MAX_ERROR), where MAX_FITNESS is some large constant and MAX_ERROR is the maximum possible error value. This is the default.
#   inverse: The fitness is calculated as MAX_FITNESS / (1 + error), where MAX_FITNESS is some large constant.
fitness.function.error.conversion.type=inverse
# The method used to calculate the performance. 
#   proportional: The performance is calculated as <em>error / MAX_ERROR</em>, where MAX_ERROR is the maximum possible error value. This is the default.
#   percent-correct: The performance is calculated as the percentage of correct trials (see {@link FITNESS_ACCEPTABLE_ERROR_KEY}).
fitness.function.performance.type=proportional
# The absolute value that an output can differ from the target output and still be considered correct (i.e. the acceptable error margin). Used for calculating the percentage of trials for which the correct output was given. Default is 0.1.
fitness.function.error.acceptable=0.1
# Whether to log the evaluation of the champ for each trial to a text file: N < 0 indicates no logging, N=0 indicates 
# only at the end of evolution, N > 0 indicates every N generations and after evolution has finished.
fitness.function.log.champ.evaluation.pergenerations=25


################
# CPPN/AnjiNet #
################
#input and output size determined by hyperneat settings
#stimulus.size=7
#response.size=1
# The type of activation function to use in the CPPN, "random" means a function will be randomly picked.
initial.topology.activation=random
initial.topology.fully.connected=true
# if initial.topology.fully.connected=false then the initial population will be generated by applying the mutation operators to clones of the 
# sample chromosome (which will just contain the input and output neurons and optionally some hidden neurons (see initial.topology.num.hidden.neurons)).
# The mutation rates of the operators may be temporarily increased during this process by setting initial.topology.mutation.factor to a value greater than 1.
initial.topology.mutation.factor=20
initial.topology.num.hidden.neurons=0
initial.topology.activation.input=linear
# Using an activation function with range [0, 1] or [-1, 1] causes the transcriber to scale the output to the substrate weight range, rather than truncating it to that range.
initial.topology.activation.output=linear
# The activation function types that may be added to the CPPN if initial.topology.activation=random.
initial.topology.activation.random.allowed=sigmoid, gaussian, sine, absolute
# The probability weight of each function in initial.topology.activation.random.allowed being selected.
#initial.topology.activation.random.probabilities=1.0, 1.0, 1.0, 1.0
recurrent=disallowed
recurrent.cycles=1
#[1, 500]
weight.max=50
weight.min=-50


#############
# HyperNEAT #
#############
ann.transcriber.class=com.ojcoleman.ahni.transcriber.HyperNEATTranscriberBain
ann.transcriber.neuron.model=com.ojcoleman.bain.neuron.rate.ClampedLinearNeuronCollection
ann.transcriber.synapse.model=com.ojcoleman.bain.synapse.rate.FixedSynapseCollection

#Set to true to restrict the substrate network to a strictly feed-forward topology.
ann.hyperneat.feedforward=true
#For recurrent networks, the number of activation cycles to perform each time the substrate network is presented with new input and queried for its output.
#ann.hyperneat.cyclesperstep=4  not required for feed forward
#Enable bias connections in the substrate network.
ann.hyperneat.enablebias=true
#If true indicates that the CPPN should receive the delta value for each axis between the source and target neuron coordinates
ann.hyperneat.includedelta=true
#If true indicates that the CPPN should receive the angle in the XY plane between the source and target neuron coordinates (relative to the line X axis).
ann.hyperneat.includeangle=false
#If true indicates that instead of using a separate output from the CPPN to specify weight values for each weight layer in a feed-forward network, the layer coordinate is input to the CPPN and only a single output from CPPN is used to specify weight values for all weight layers.
ann.hyperneat.useinputlayerencoding=false

#The minimum CPPN output required to produce a non-zero weight in the substrate network. 
ann.hyperneat.connection.expression.threshold=0.2
# If true use the Link Expression Output enhancement instead of a threshold (ie instead of ann.hyperneat.connection.expression.threshold)
ann.hyperneat.leo=false
# Set a threshold for the Link Expression Output (LEO). Default is 0.
ann.hyperneat.leo.threshold=0.2
# Enable multiplying the threshold for the Link Expression Output (LEO) by the square of the distance between the
# source and target neurons. Default is false.
ann.hyperneat.leo.threshold.factordistance=false
# Multiply the threshold for the Link Expression Output (LEO) by a factor depending on the direction of
# the synapse with respect to the Z axis. Three comma-separated values are required for the reverse, neutral and
# forward directions, respectively. This could be used to help inhibit non-feed-forward, recurrent links. Default
# is 1,1,1 (i.e. no directional factor).
ann.hyperneat.leo.threshold.directionalfactor=1,1,1
# Enable or disable seeding of the initial population of CPPNs to incorporate a bias towards local connections via the Link Expression Output (LEO). Default is "false".
ann.hyperneat.leo.localityseeding=false

# If true use the Neuron Expression Output. This is similar to the LEO, but allows disabling neurons.
# It is implemented by disabling all synapses connected to a disabled neuron (the neuron itself carries on as usual).
ann.hyperneat.neo=false
# Set a threshold for the Neuron Expression Output (NEO). Default is 0.
ann.hyperneat.neo.threshold=0.2

#Limits the incoming connections to a target neuron to include those from source neurons within the specified range of the target neuron. Set this to -1 to disable it.
ann.hyperneat.connection.range=-1
#Minimum and maximum weight values in the substrate network.
ann.transcriber.connection.weight.min=-1
ann.transcriber.connection.weight.max=1

#The number of layers in the substrate network. NOTE: this has been deprecated, the number of layers is now 
#determined by the number of elements in ann.hyperneat.width and ann.hyperneat.height.
#ann.hyperneat.depth=2
#The height and width of each layer in the network, including input and output layers and starting with the input layer.
ann.hyperneat.height=2, 2
ann.hyperneat.width=2, 2

# The coordinate range of neurons in the substrate in each dimension. This is 
# used to determine the input to the CPPN for a given substrate neuron location. 
# Defaults to "0, 1".
ann.hyperneat.range.x=0, 1
ann.hyperneat.range.y=0, 1
# Inputs are at z=0, outputs at z=1.
ann.hyperneat.range.z=0, 1 

# The coordinates of neurons in a specified layer. The layer must be specified as part of the property key/name,
# e.g. to specify the coordinates of two neurons in the layer with index 2 (counting from 0):
#   ann.hyperneat.layer.positions.2=(-0.5, 0, 0), (0.5, 0, 0)
# For 2D layers the coordinates should be specified in row-packed order (i.e. one row after another, where a single
# row has the same y index/coordinate). Coordinates must be specified for all neurons in the given layer. If the z
# coordinate is not given it will be set to the default for the layer.
 # NOTE: coordinates should be given with respect to ann.hyperneat.range settings.
#ann.hyperneat.layer.positions.2=(-0.5, 0, 0), (0.5, 0, 0)

# Optionally specify an initial seed CPPN from which the initial population is created.
# Each entry either specifies a hidden neuron or a connection. Entries are comma-separated, 
# with the parameters for each entry separated by colons (:). The parameters for a hidden 
# neuron are an ID and the activation function, for example "my hidden 2:sigmoid" (the ID can
# be anything except for the IDs listed below for input and output neurons). The parameters 
# for a connection are a "c" to indicate this is a connection entry, the source neuron, the 
# target neuron and the weight, for example "c:xs:my hidden 2:-0.5". Input and output neurons
# use the following labelling scheme:
# b: CPPN bias input
# [xyz][st]: x, y or z coordinate input for source or target neuron.
# wN: weight output for source layer N, counting from 0 (N=0 if ann.hyperneat.useinputlayerencoding=true).
# wB: bias output for source layer N, counting from 0 (N=0 if ann.hyperneat.useinputlayerencoding=true).
# wL: LEO output for source layer N, counting from 0 (N=0 if ann.hyperneat.useinputlayerencoding=true).
# Note that the available inputs and outputs is dependent on other parameters.
# Example (note that property values can span multiple lines by ending each line with \):
#hyperneat.cppn.initial=\
#h0:gaussian, \
#h1:gaussian, \
#h2:sigmoid, \
#h3:step, \
#c:xs:h1:1, \
#c:zs:h0:1, \
#c:xt:h1:-1, \
#c:zt:h0:-1, \
#c:b:h0:1, \
#c:b:h3:-1, \
#c:h0:h2:1, \
#c:h1:h3:1, \
#c:h2:w0:1, \
#c:h3:l0:1


#############
# persistence
#############
persistence.class=com.anji.persistence.FilePersistence
persistence.base.dir=./db
persist.enable=false
persist.all=false
persist.champions=false
persist.last=false
persist.load.genotype=false
id.file=./db/id.xml
neat.id.file=./db/neatid.xml

##############
# presentation
##############
presentation.generate=false
presentation.dir=./nevt

#########
# logging
#########
# How often to produce a line in the log containing a brief summary of the current progress.
log.pergenerations=1

# FileAppenders with the name RunLog receive special treatment: for each run the output will be directed to a file 
# with the name specified by log4j.appender.RunLog.File in the directory [output.dir]/[run number]/
log4j.rootLogger=INFO, C
log4j.appender.C=org.apache.log4j.ConsoleAppender
#log4j.appender.F=org.apache.log4j.FileAppender
#log4j.appender.F=org.apache.log4j.RollingFileAppender
#log4j.appender.F.File=/home/data/ai/unsw/project/software/anji/log/or3.log
#log4j.appender.F.MaxFileSize=10MB
#log4j.appender.F.MaxBackupIndex=20
log4j.appender.C.layout=org.apache.log4j.PatternLayout
#log4j.appender.F.layout=org.apache.log4j.PatternLayout
log4j.appender.C.layout.ConversionPattern=%-5p %m%x%n
#log4j.appender.F.layout.ConversionPattern=%-5p %m%x%n

################
# other output #
################
# Where to store output files produced by the experiment.
output.dir=../bain-test-pass-through-flip
# Whether to log the champ to a text file and/or image. N < 0 indicates no logging, N=0 indicates 
# only at the end of evolution, N > 0 indicates every N generations and after evolution has finished.
log.champ.tostring=25
log.champ.toimage=25
# Whether to produce a file containing the size, creation and extinction of each species over time. Default is false.
log.species_history=true



#######################################
# parameter tuning via ParameterTuner #
#######################################

parametertuner.tune.0.prop=fitness.function.generic_novelty.sample_count
parametertuner.tune.0.type=integer
parametertuner.tune.0.adjust.type=factor
parametertuner.tune.0.adjust.amount=2
parametertuner.tune.0.initial=4
parametertuner.tune.0.min=1
parametertuner.tune.0.max=1000

parametertuner.tune.1.prop=initial.topology.activation.random.allowed
parametertuner.tune.1.type=discrete
parametertuner.tune.1.adjust.type=delta
parametertuner.tune.1.adjust.amount=1
parametertuner.tune.1.initial=0
parametertuner.tune.1.discrete_values=sigmoid, gaussian, sine, absolute

parametertuner.numruns=75
parametertuner.numgens=1000
parametertuner.solvedperformance=0.98
parametertuner.htcondor=\
  jar_files = ../../../lib/aparapi.jar ../../../lib/bain.jar ../../../lib/commons-lang3-3.1.jar ../../../lib/commons-math3-3.1.1.jar ../../../lib/jakarta-regexp-1.3.jar ../../../lib/jcommander.jar ../../../lib/log4j.jar ../../../lib/wildcard-1.03.jar
  Rank                  = kflops \n \
  +RequiresWholeMachine = True \n \
  notification = Never
